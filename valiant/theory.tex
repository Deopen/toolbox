The classical dynamic {\sc cyk} algorithm for parsing context-free grammars runs in cubic time (in terms of the input word). 
In this chapter we present a parsing algorithm of  Valiant~\cite{Valiant:1975bn}, which parses  context-free languages  in approximately the same time as (Boolean) matrix multiplication.  For readers who do not like matrices, multiplying two $n \times n$  Boolean matrices  is the same as computing the composition $R \circ S$ of two  binary relations $R,S \subseteq \set{1,\ldots,n}^2$.
The naive algorithm for this problem runs in time $n^3$, but smarter algorithms run faster, e.g.~the Strassen algorithm runs in time approximately $\Oo(n^{2.8704})$, and the record holder as of  2017 is $\Oo(n^{2.3727})$, see~\cite{Williams:2012gs}

\begin{theorem}
	\label{thm:valiant}
	Assume that  multiplication of $n \times n$ Boolean matrices can be computed in time $\Oo(n^\omega)$ for some real number $\omega$. Then membership in a context-free language can be decided in time at most
	\begin{align*}
\mathrm{poly}(\Gg) \cdot n^\omega \cdot \log^2(n) \qquad \text{where $\Gg$ is the grammar and $n$ is the length of the input.}\end{align*}
\end{theorem}

For the rest of this chapter, fix $\omega$ and a context-free grammar $\Gg$. We assume that the grammar is in Chomsky Normal Form, i.e.~every rule is of the form $X \leftarrow YZ$ or $X \leftarrow a$, where $X,Y,Z$ are nonterminals and $a$ is a terminal. A grammar can be converted into Chomsky Normal Form in polynomial time, so this assumption can be made without loss of generality. 
\newcommand{\ptrip}[3]{#1 \stackrel {#2} \to #3}
Define a length $n$ \emph{parse matrix} to be a family
%\begin{align*}
%  \ptrip i X j \qquad \text{where $i<j$ are in $\set{1,\ldots,n}$ and $X$ is a nonterminal.}
%\end{align*}
\begin{align*}
M =   \set{M_X}_{\text{$X$ is a nonterminal}}
\end{align*}
such that each $M_X$ is a family of intervals in $\set{1,\ldots,n}$. Here an interval is a set of numbers connected by the successor relation, like this:
\mypic{106}
 The intuition is that, given an input word, we put into $M_X$ all those intervals that correspond to infixes of the input word which  can be generated by nonterminal $X$.
For parse matrices $M,N$ of same length, define their product $M \circ N$ by
\begin{align*}
(M \circ N)_X \eqdef \bigcup_{X \to YZ} M_Y \circ M_Z
\end{align*}
where the union ranges over rules of the grammar and $M_Y \circ M_Z$ is defined to be the family of intervals that can be decomposed as a disjoint union of an interval from $M_Y$ followed by an interval from $M_Z$, as in the following picture:
\mypic{105}
A family of intervals contained in $\set{1,\ldots,n}$ can be seen as the binary relation over $\set{0,\ldots,n}$, where an interval $\set{i,\ldots,j}$ is represented as a pair $(i-1,j)$. Under this representation, product of sets of intervals is the same as composing binary relations, which in turn is the same as multiplying Boolean matrices. Hence, we get the following observation.

\begin{lemma}\label{lem:matrix-mult}
	For length $n$ parse matrices, product can be computed in time $\Oo(n^\omega)$.
\end{lemma}
We say that a parse matrix $M$ is \emph{closed} if it satisfies $M \circ M \subseteq M$, and we say that it is closed  on an interval $I \subseteq \set{1,\ldots,n}$ if it is closed when restricted to intervals contained in $I$.  For a parse matrix $M$, define its \emph{closure} $M^*$ to be the least (with respect to inclusion) parse matrix that contains $M$ and is closed.


\begin{proposition}\label{prop:combine-halves}
There is an algorithm which runs in time, call it $T(n)$,  at most
\begin{align*}
\mathrm{poly}(\Gg) \cdot \log(n) \cdot n^\omega
\end{align*}
and which computes the closure of a length $2n$ parse matrix,  assuming that it is closed on the intervals $\set{1,\ldots,n}$ and $\set{n+1,\ldots,2n}$.
\end{proposition}

Before proving the proposition, we show how it implies the Theorem~\ref{thm:valiant}.

\begin{proof}[Proof of Theorem~\ref{thm:valiant}]
Suppose that we want to know if the grammar $\Gg$ generates a word $w$ of length $n$. Define $M$ to be the length $n$ parse matrix where $M_X$ contains intervals $\set{i}$ such that nonterminal $X$ generates the $i$-th letter of $w$, using a rule of the form $X \to a$.
This parse matrix can be computed in time linear in $n$. 
The word $w$ is generated by the grammar if and only if the closure $M^*$ contains the interval  $\set{1,\ldots,n}$ on the component corresponding to the starting nonterminal. It suffices therefore to compute the closure $M^*$. To make the computation easier, suppose that the length of the word is a power of two, i.e.~$n=2^k$. We do a divide an conquer approach: we compute the closures of the parse matrix for the first and second halves of $w$  (using a recursive procedure), and then combine these using the algorithm from Proposition~\ref{prop:combine-halves}. The running time of this algorithm is at most
\begin{align}\label{eq:valiant-running-time}
  T(n) + 2T(\frac n 2) + \cdots + 2^k T(\frac n {2^k}).
\end{align}	
Because $T(n)$ is at least linear, it follows that
\begin{align*}
  2^i T(\frac n {2^i}) \le T(n),
\end{align*}
which shows that the running time~\eqref{eq:valiant-running-time} is at most $\log n$ times slower than $T(n)$, thus proving the theorem, given the bounds on $T(n)$ from Proposition~\ref{prop:combine-halves}. \end{proof}

It remains to prove the proposition. We use the following lemma.



\begin{lemma}\label{lem:overlap}
Suppose that $M$ is a length $k+2n$ parse matrix that is closed on the intervals $A \cup B$ and $B \cup C$ as depicted below: \mypic{59}
Then the closure $M^*$  can be computed in time 
 $ \mathrm{poly}(\Gg)  \cdot n^\omega + T(n)$.
\end{lemma}
\begin{proof}  
Define $N$ to be $M \cup M \circ M$ restricted to intervals that contain $B$ or are disjoint with $B$. The main observation in the lemma is
 \begin{align}\label{eq:matrix}
  	M^* = M \cup N^*,
\end{align}
where the sum above is component-wise (recall that a parse matrix is a family of sets of intervals).
Before proving the above equality, we note that the right side of the above equality can be computed in time as in the statement of the lemma, thus proving the lemma.  By Lemma~\ref{lem:matrix-mult}, $N$ can be computed in time $\mathrm{poly}(\Gg)  \cdot n^\omega$. Because the matrix $M$ was closed over intervals $A$ and $C$, it follows that $N$ is also closed over these intervals. Since all entries of $N$ contain $B$ or are disjoint with $B$, it is essentially a matrix of length $2n$ whose first and second halves are closed. It follows that $N^*$ can be computed in time $T(n)$. 

It remains to prove the equality~\eqref{eq:matrix}. The inclusion $\supseteq$ is immediate, it remains to justify the inclusion $\subseteq$.  
We need to show that if $M^*$ contains interval $I$ on nonterminal $X$, then this is true for $M \cup N^*$. If $I$ is contained in $A \cup B$ or $B \cup C$, then this implication holds by  the closure assumptions on $M$. The remaining case is when $I$ contains $B$. The reason for $M^*$ containing $I$ on nonterminal $X$  is  a parse tree as described in the following picture:
\mypicc{25}
In the parse tree, use red consider the smallest interval which contains $B$, and use yellow for the descendants of the red interval:
\mypicc{26} 
By minimality, each yellow interval is contained in either  $A \cup B$ or  $B \cup C$, and therefore belongs to  $M$ by the closure assumptions on $M$.  Therefore, the red itself belongs to $M \circ M$. The red interval contains $B$, and the blue intervals are disjoint with $B$, therefore the red and blue intervals are in $N$. It follows that the red and blue intervals form a parse tree corresponding  to the matrix  $N^*$. 
\end{proof}


\begin{proof}[Proof of Proposition~\ref{prop:combine-halves}]
	Here is the algorithm. Suppose that $M$ is a length $2n$ parse matrix which is closed on its first and second halves, as in the statement of the proposition. Let us write $A,B,C,D$ for the intervals describing the four quarters of $2n$, as in the following picture: \mypic{55}
As in Lemma~\ref{lem:overlap},	the blue rectangles indicate the intervals which are closed. 
	\begin{enumerate}
	\item By induction,  compute the closure of the interval $B \cup C$:
	\mypic{56}
		\item 	Using Lemma~\ref{lem:overlap} twice,   compute the closures of $A \cup B \cup C$ and  $B \cup C \cup D$:
\mypic{57}
		\item Using Lemma~\ref{lem:overlap}, compute the closure of $A \cup B \cup C \cup D$:
\mypic{58}
	\end{enumerate}
The cost of the above procedure is:
\begin{align*}
  T(n) = \underbrace{T(n/2)}_{\text{step 1}} +  \underbrace{2 \cdot (T(n/2) + c \cdot n^\omega)}_{\text{step 2}} + \underbrace{T(n/2) +  c \cdot n^\omega}_{\text{step 3}} 
\end{align*}
for some $c$ polynomial in the grammar. Summing up,
\begin{align*}
T(n) =   4T(n/2) + 3c \cdot n^\omega.
\end{align*}
Reasoning as in the end of the proof of Theorem~\ref{thm:valiant}, we get
\begin{align*}
  T(n) = 3c \cdot n^\omega + 4 \cdot 3c \cdot (\frac n 2)^\omega + \cdots + 4^k \cdot 3c \cdot (\frac n {2^k})^\omega.
\end{align*}	
Because $n^\omega$ is at least quadratic (an algorithm for matrix multiplication must at least read two  $n \times n$ matrices), it follows that 
\begin{align*}
  2^i  \cdot (\frac n {2^i})^\omega \le     n^\omega,
\end{align*}
which gives the bound in the proposition.
\end{proof}

